{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from unet_model import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, interlaced_dir, gtruth_dir, scale=1):\n",
    "        self.interlaced_dir = interlaced_dir\n",
    "        self.gtruth_dir = gtruth_dir\n",
    "        self.scale = scale\n",
    "        self.transform = transforms.Compose([transforms.RandomCrop(256), transforms.ToTensor()])\n",
    "        \n",
    "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
    "\n",
    "        self.ids = [splitext(file)[0] for file in listdir(interlaced_dir)]\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, pil_img, scale):\n",
    "        pil_img = pil_img / 255.0\n",
    "        \n",
    "        return pil_img\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        gtruth_file = glob(self.gtruth_dir + idx + '.*')\n",
    "        interlaced_file = glob(self.interlaced_dir + idx + '.*')\n",
    "\n",
    "        assert len(gtruth_file) == 1, \\\n",
    "            f'Either no mask or multiple masks found for the ID {idx}: {gtruth_file}'\n",
    "        assert len(interlaced_file) == 1, \\\n",
    "            f'Either no image or multiple images found for the ID {idx}: {interlaced_file}'\n",
    "        gtruth = Image.open(gtruth_file[0])\n",
    "        interlaced = Image.open(interlaced_file[0])\n",
    "\n",
    "        assert interlaced.size == gtruth.size, \\\n",
    "            f'Image and mask {idx} should be the same size, but are {interlaced.size} and {gtruth.size}'\n",
    "\n",
    "        interlaced = self.transform(interlaced)\n",
    "        interlaced = self.preprocess(interlaced, self.scale)\n",
    "        gtruth = self.transform(gtruth)\n",
    "        gtruth = self.preprocess(gtruth, self.scale)\n",
    "\n",
    "        return interlaced, gtruth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interlaced_dir = \"./dataset/interlaced/\"\n",
    "gtruth_dir = \"./dataset/ground_truth/\"\n",
    "img_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              epochs=5,\n",
    "              batch_size=1,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_cp=True,\n",
    "              img_scale=1):\n",
    "\n",
    "    dataset = OurDataset(interlaced_dir, gtruth_dir, img_scale)\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "    for inter, truth in tqdm(train_loader):\n",
    "#         f, axarr = plt.subplots(1,2)\n",
    "#         axarr[0].imshow(inter[0].permute(1,2,0))\n",
    "#         axarr[1].imshow(truth[0].permute(1,2,0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/16986 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = UNet(n_channels=3, bilinear=True)\n",
    "train_net(net=net,\n",
    "          epochs=10,\n",
    "          batch_size=5,\n",
    "          lr=0.01,\n",
    "          device=device,\n",
    "          img_scale=1,\n",
    "          val_percent=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
