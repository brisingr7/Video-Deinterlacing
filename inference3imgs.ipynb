{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e340f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from unet_model3 import UNet\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449a9152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/99738 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1071/99738 [05:01<7:42:14,  3.56it/s] \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_inter/1071.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-efd29274309e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#load GT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     gt = Image.open(gt_path+ground_truths[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"{i}.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print(inter_path+f\"{i}.npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_inter/1071.npy'"
     ]
    }
   ],
   "source": [
    "gt_path = \"dataset3/interlaced/\"\n",
    "inter_path = \"test_inter/\"\n",
    "ground_truths = os.listdir(gt_path)\n",
    "interlaced = os.listdir(inter_path)\n",
    "\n",
    "model = UNet(n_channels=9)\n",
    "model.load_state_dict(torch.load(\"model3-fixed-9.pth\"))\n",
    "print(\"loaded model successfully\")\n",
    "model = model.to(torch.device('cuda'))\n",
    "\n",
    "for i in tqdm(range(len(ground_truths))):\n",
    "    #load GT\n",
    "#     gt = Image.open(gt_path+ground_truths[i])\n",
    "    inter = np.load(inter_path+f\"{i}.npy\")\n",
    "#     print(inter_path+f\"{i}.npy\")\n",
    "    inter1 = inter[:,:,0:3]\n",
    "#     print(inter1.shape)\n",
    "    inter2 = inter[:,:,3:6]\n",
    "    inter3 = inter[:,:,6:9]\n",
    "#     inter1 = inter1[:,:,::-1]\n",
    "#     inter2 = inter2[:,:,::-1]\n",
    "#     inter3 = inter3[:,:,::-1]\n",
    "#     print(inter1.shape)\n",
    "    inter = torch.tensor(inter)\n",
    "    inter = inter/255\n",
    "    inter = inter.permute(2,0,1)\n",
    "    inter = torch.unsqueeze(inter, 0)\n",
    "    inter = inter.to(torch.device('cuda'))\n",
    "    output = model(inter)\n",
    "    output = output*255\n",
    "    output = output.clip(0,255)\n",
    "    out_np = np.array(output.cpu().detach()).astype(np.uint8)\n",
    "    out_np = np.squeeze(out_np)\n",
    "    out_np = np.transpose(out_np, (1,2,0))\n",
    "    im = Image.fromarray(out_np)\n",
    "    im.save(f\"inference_3_images_l1_loss/{i}.bmp\")\n",
    "#     IPython.display.display(Image.fromarray(inter1))\n",
    "#     IPython.display.display(Image.fromarray(inter2))\n",
    "#     IPython.display.display(Image.fromarray(inter3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e777d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
